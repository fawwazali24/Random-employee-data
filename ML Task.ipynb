{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f105907-c7d7-4c67-9385-007200b30c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d705bf3-02a1-41bd-ba09-adf3d8699b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to preprocess the data \n",
    "def data_preprocessing(task_1a_dataframe):\n",
    "    encoded_dataframe=task_1a_dataframe.copy()\n",
    "    #mapping some columns as numbers for the neural network\n",
    "    encoded_dataframe['Education']=encoded_dataframe['Education'].map({'Bachelors':1,'Masters':2,'PHD':3})\n",
    "    encoded_dataframe['City']=encoded_dataframe['City'].map({'Bangalore':1,'New Delhi':2,'Pune':3})\n",
    "    encoded_dataframe['Marital Status']=encoded_dataframe['Marital Status'].map({'Married':2,'Single':1})\n",
    "    encoded_dataframe['Gender']=encoded_dataframe['Gender'].map({'Male':0,'Female':1})\n",
    "    encoded_dataframe['EverBenched']=encoded_dataframe['EverBenched'].map({'No':0,'Yes':1})\n",
    "    scaler=StandardScaler()\n",
    "    encoded_dataframe[['Age','JoiningYear']]=scaler.fit_transform(encoded_dataframe[['Age','JoiningYear']])\n",
    "    return encoded_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720d862f-46c3-41a1-8ccf-b30dc3e548de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract required inputs and outputs from the data\n",
    "def identify_features_and_targets(encoded_dataframe):\n",
    "    targets=encoded_dataframe[['LeaveOrNot']]\n",
    "    features=encoded_dataframe.drop('LeaveOrNot',axis=1)\n",
    "    features_and_targets=[features,targets]\n",
    "    return features_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6431b03e-e688-4730-b9ff-44a1160704a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the data as tensors\n",
    "def load_as_tensors(features_and_targets):\n",
    "    X=features_and_targets[0]\n",
    "    Y=features_and_targets[1]\n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.1,random_state=42) #splitting the data for training and testing\n",
    "    x_train=np.array(x_train)\n",
    "    y_train=np.array(y_train)\n",
    "    x_test=np.array(x_test)\n",
    "    y_test=np.array(y_test)\n",
    "    x_train=torch.FloatTensor(x_train)\n",
    "    x_test=torch.FloatTensor(x_test)\n",
    "    y_train=torch.LongTensor(y_train)\n",
    "    y_test=torch.LongTensor(y_test)\n",
    "    data_train=TensorDataset(x_train,y_train)\n",
    "    dataloader=DataLoader(data_train,batch_size=100,shuffle=True)\n",
    "    tensors_and_iterable_training_data=[x_train,y_train,x_test,y_test,dataloader]\n",
    "    return tensors_and_iterable_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bffe0c5e-df08-40f0-b1f5-ee4f8d962c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the layers in the network\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self,f_in=9,hidden1=20,hidden2=15,hidden3=8,f_out=1):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.hiddenlayer1=nn.Linear(f_in,hidden1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hiddenlayer2=nn.Linear(hidden1,hidden2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hiddenlayer3=nn.Linear(hidden2,hidden3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.outputlayer=nn.Linear(hidden3,f_out)\n",
    "        self.sigmoid=nn.Sigmoid()   \n",
    "    def forward(self, predicted_output):\n",
    "        predicted_output=F.relu(self.hiddenlayer1(predicted_output))\n",
    "        #predicted_output=self.relu(predicted_output)\n",
    "        predicted_output=F.relu(self.hiddenlayer2(predicted_output))\n",
    "        predicted_output=F.relu(self.hiddenlayer3(predicted_output))\n",
    "        predicted_output=F.sigmoid(self.outputlayer(predicted_output))\n",
    "        #predicted_output=self.sigmoid(predicted_output) \n",
    "        return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc85bc1a-b810-4d30-b802-e3dfd6dcca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary loss fucntion to be used as output is in binary format\n",
    "def model_loss_function():\n",
    "    loss_function=nn.BCELoss()\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd26034-4bc1-4731-85e2-a20712354c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimizer(model):\n",
    "    optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d2a11c6-14fe-481f-a405-8b5c04198602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_number_of_epochs():\n",
    "    number_of_epochs=50\n",
    "    return number_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9a418b-1995-4142-821d-6b1becf6c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer):\n",
    "    x_train,y_train,x_test,y_test,dataloader=tensors_and_iterable_training_data\n",
    "    for epoch in range(number_of_epochs):\n",
    "        model.train()  #train the model on the inputs provided\n",
    "        for batch_x,batch_y in dataloader:\n",
    "            output=model.forward(batch_x)\n",
    "            loss=loss_function(output,batch_y.float())\n",
    "            #backpass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{number_of_epochs}], Loss: {loss.item():.4f}')  #printing loss after each epoch\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6054efa2-df15-4ee5-8ffc-135f9f6bc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
    "    trained_model.eval()\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        x_test=tensors_and_iterable_training_data[2]\n",
    "        y_test=tensors_and_iterable_training_data[3]\n",
    "        output=trained_model(x_test)\n",
    "        predicted=(output>0.5).float()\n",
    "        #_,predicted=torch.max(output.data,1)\n",
    "        total+=y_test.size(0)\n",
    "        correct+=(predicted==y_test).sum().item()\n",
    "    model_accuracy=correct/total   #calculating the accuracy of the model on new data\n",
    "    return model_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65d75666-39bc-4a63-902b-11467c18d2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.6325\n",
      "Epoch [2/50], Loss: 0.6579\n",
      "Epoch [3/50], Loss: 0.6229\n",
      "Epoch [4/50], Loss: 0.5853\n",
      "Epoch [5/50], Loss: 0.5212\n",
      "Epoch [6/50], Loss: 0.5252\n",
      "Epoch [7/50], Loss: 0.5579\n",
      "Epoch [8/50], Loss: 0.5720\n",
      "Epoch [9/50], Loss: 0.5695\n",
      "Epoch [10/50], Loss: 0.5592\n",
      "Epoch [11/50], Loss: 0.5077\n",
      "Epoch [12/50], Loss: 0.5755\n",
      "Epoch [13/50], Loss: 0.5666\n",
      "Epoch [14/50], Loss: 0.5651\n",
      "Epoch [15/50], Loss: 0.5117\n",
      "Epoch [16/50], Loss: 0.5294\n",
      "Epoch [17/50], Loss: 0.4314\n",
      "Epoch [18/50], Loss: 0.4918\n",
      "Epoch [19/50], Loss: 0.6115\n",
      "Epoch [20/50], Loss: 0.4687\n",
      "Epoch [21/50], Loss: 0.3818\n",
      "Epoch [22/50], Loss: 0.5269\n",
      "Epoch [23/50], Loss: 0.5106\n",
      "Epoch [24/50], Loss: 0.4477\n",
      "Epoch [25/50], Loss: 0.4684\n",
      "Epoch [26/50], Loss: 0.4353\n",
      "Epoch [27/50], Loss: 0.3859\n",
      "Epoch [28/50], Loss: 0.4169\n",
      "Epoch [29/50], Loss: 0.4703\n",
      "Epoch [30/50], Loss: 0.4611\n",
      "Epoch [31/50], Loss: 0.3816\n",
      "Epoch [32/50], Loss: 0.4796\n",
      "Epoch [33/50], Loss: 0.3175\n",
      "Epoch [34/50], Loss: 0.3871\n",
      "Epoch [35/50], Loss: 0.4650\n",
      "Epoch [36/50], Loss: 0.3729\n",
      "Epoch [37/50], Loss: 0.3795\n",
      "Epoch [38/50], Loss: 0.3142\n",
      "Epoch [39/50], Loss: 0.3861\n",
      "Epoch [40/50], Loss: 0.3887\n",
      "Epoch [41/50], Loss: 0.4267\n",
      "Epoch [42/50], Loss: 0.3083\n",
      "Epoch [43/50], Loss: 0.3547\n",
      "Epoch [44/50], Loss: 0.3524\n",
      "Epoch [45/50], Loss: 0.4189\n",
      "Epoch [46/50], Loss: 0.4637\n",
      "Epoch [47/50], Loss: 0.3022\n",
      "Epoch [48/50], Loss: 0.5160\n",
      "Epoch [49/50], Loss: 0.4840\n",
      "Epoch [50/50], Loss: 0.4932\n",
      "Accuracy on the test set = 0.8168103448275862\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "\t# reading the provided dataset csv file using pandas library and \n",
    "\t# converting it to a pandas Dataframe\n",
    "\ttask_2_dataframe = pd.read_csv('task_2_dataset.csv')\n",
    "\n",
    "\t# data preprocessing and obtaining encoded data\n",
    "\tencoded_dataframe = data_preprocessing(task_2_dataframe)\n",
    "\n",
    "\t# selecting required features and targets\n",
    "\tfeatures_and_targets = identify_features_and_targets(encoded_dataframe)\n",
    "\n",
    "\t# obtaining training and validation data tensors and the iterable\n",
    "\t# training data object\n",
    "\ttensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
    "\t\n",
    "\t# model is an instance of the class that defines the architecture of the model\n",
    "\tmodel = Predictor()\n",
    "\n",
    "\t# obtaining loss function, optimizer and the number of training epochs\n",
    "\tloss_function = model_loss_function()\n",
    "\toptimizer = model_optimizer(model)\n",
    "\tnumber_of_epochs = model_number_of_epochs()\n",
    "\n",
    "\t# training the model\n",
    "\ttrained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data, \n",
    "\t\t\t\t\tloss_function, optimizer)\n",
    "\n",
    "\t# validating and obtaining accuracy\n",
    "\tmodel_accuracy = validation_function(trained_model,tensors_and_iterable_training_data)\n",
    "\tprint(f\"Accuracy on the test set = {model_accuracy}\")\n",
    "\n",
    "\tX_train_tensor = tensors_and_iterable_training_data[0]\n",
    "\tx = X_train_tensor[0]\n",
    "\tjitted_model = torch.jit.save(torch.jit.trace(model, (x)), \"task_2_trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3ec4c6-d2d9-46a9-b3a0-c09be8de7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Education': ['Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Masters', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', \n",
    "                  'Masters', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Masters', \n",
    "                  'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Bachelors', 'Masters', 'Bachelors', 'Bachelors'],\n",
    "    'JoiningYear': [2018, 2014, 2018, 2015, 2016, 2017, 2017, 2016, 2018, 2017, \n",
    "                    2017, 2014, 2016, 2012, 2016, 2014, 2013, 2014, 2017, 2016, \n",
    "                    2015, 2014, 2013, 2016, 2013, 2016, 2016, 2012, 2017, 2012],\n",
    "    'City': ['New Delhi', 'Bangalore', 'Bangalore', 'Pune', 'Pune', 'New Delhi', 'Pune', 'Bangalore', 'Pune', 'Bangalore', \n",
    "             'Pune', 'Pune', 'Bangalore', 'Bangalore', 'Pune', 'Bangalore', 'Pune', 'New Delhi', 'Pune', 'Bangalore', \n",
    "             'Bangalore', 'Bangalore', 'Pune', 'New Delhi', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'New Delhi'],\n",
    "    'PaymentTier': [2, 3, 3, 2, 3, 2, 2, 3, 3, 3, \n",
    "                    3, 3, 3, 3, 3, 3, 1, 3, 2, 3, \n",
    "                    3, 1, 2, 2, 3, 3, 3, 3, 1, 3],\n",
    "    'Age': [34, 34, 26, 30, 23, 37, 29, 40, 32, 34, \n",
    "            24, 34, 22, 37, 34, 23, 28, 38, 37, 27, \n",
    "            23, 30, 31, 22, 30, 37, 34, 27, 29, 29],\n",
    "    'Gender': ['Female', 'Female', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Male', 'Male', \n",
    "               'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Female', 'Male', \n",
    "               'Male', 'Female', 'Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Male', 'Male'],\n",
    "     'Marital Status': [\n",
    "    'Married', 'Married', 'Married', 'Married', 'Married', 'Single', 'Married', 'Married', 'Single', 'Married',\n",
    "    'Married', 'Married', 'Single', 'Single', 'Single', 'Married', 'Single', 'Married', 'Married', 'Single',\n",
    "    'Single', 'Married', 'Single', 'Married', 'Single', 'Single', 'Single', 'Married', 'Single', 'Single'],\n",
    "    'EverBenched': ['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', \n",
    "                    'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', \n",
    "                    'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No'],\n",
    "    'ExperienceInCurrentDomain': [0, 2, 4, 0, 1, 2, 2, 5, 5, 0, \n",
    "                                  2, 4, 0, 4, 3, 1, 3, 2, 0, 5, \n",
    "                                  1, 3, 2, 0, 3, 2, 2, 5, 3, 3],\n",
    "    'LeaveOrNot': [1, 0, 1, 1, 0, 0, 1, 0, 1, 0, \n",
    "                   1, 0, 0, 0, 0, 0, 1, 0, 1, 1, \n",
    "                   0, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n",
    "}\n",
    "\n",
    "task_1a_dataframe = pd.DataFrame(data)\n",
    "encoded_dataframe2 = data_preprocessing(task_1a_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea32e01-8db5-4485-8b64-4f4a581ab495",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_and_targets2 = identify_features_and_targets(encoded_dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7235c42-4c21-40aa-944c-7ae7ec9f7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "tensors_and_iterable_training_data2 = load_as_tensors(features_and_targets2)\n",
    "trained_model = torch.jit.load('task_2_trained_model.pth')\n",
    "model_accuracy = validation_function(trained_model,tensors_and_iterable_training_data2)\n",
    "print(f\"Accuracy is = {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390f23c-33a7-49a1-b188-50edf2f88048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f4e11-78a1-4cb0-b869-25b3a633d3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
